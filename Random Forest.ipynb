{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b330cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.signal import hilbert\n",
    "from antropy import sample_entropy\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb49ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = {\n",
    "    \"delta\": (0.5, 4),\n",
    "    \"theta\": (4, 8),\n",
    "    \"alpha\": (8, 13),\n",
    "    \"beta\": (13, 30),\n",
    "    \"gamma\": (30, 45)\n",
    "}\n",
    "\n",
    "def bandpower(sig, fs, band):  #filtrira signale po frekvencijama\n",
    "    low, high = band\n",
    "    b, a = butter(4, [low / (fs / 2), high / (fs / 2)], btype='band')\n",
    "    filtered = filtfilt(b, a, sig)\n",
    "    power = np.sum(filtered ** 2) / len(filtered)\n",
    "    return power "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ea75dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_esis(epoch, fs):\n",
    "    \n",
    "    energy = np.square(epoch)\n",
    "    slope = np.abs(np.diff(epoch, prepend=epoch[0]))\n",
    "    v = fs * slope\n",
    "    esis = np.sum(energy * v)\n",
    "\n",
    "    return esis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b810286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(epoch, fs = 100):\n",
    "    rms = np.sqrt(np.mean(np.square(epoch))) #ROOT MEAN SQUARE\n",
    "    mse = np.mean((epoch - np.mean(epoch)) ** 2) #MEAN SQUARED ERROR\n",
    "    mmd = np.mean(np.abs(np.diff(epoch))) #MINIMAL MAXIMAL DISTANCE\n",
    "    zcr = ((epoch[:-1] * epoch[1:]) < 0).sum() #ZERO CROSSING RATE\n",
    "    se = sample_entropy(epoch) #SAMPLE ENTROPY\n",
    "    esis = compute_esis(epoch, fs)\n",
    "\n",
    "    talasi = {ime: bandpower(epoch, fs, opseg) for ime, opseg in bands.items()}\n",
    "\n",
    "    red = {\n",
    "        \"RMS\": rms,\n",
    "        \"MSE\": mse,\n",
    "        \"MMD\": mmd,\n",
    "        \"ZCR\": zcr,\n",
    "        \"Sample Entropy\": se,\n",
    "        \"Esis\": esis,\n",
    "        \"Delta\": talasi[\"delta\"],\n",
    "        \"Theta\": talasi[\"theta\"],\n",
    "        \"Alpha\": talasi[\"alpha\"],\n",
    "        \"Beta\": talasi[\"beta\"],\n",
    "        \"Gamma\": talasi[\"gamma\"]\n",
    "    }\n",
    "\n",
    "    return [rms, mse, mmd, zcr, se, esis, talasi[\"alpha\"], talasi[\"beta\"], talasi[\"gamma\"], talasi[\"delta\"], talasi[\"theta\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bca0b382",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"C:/Analiza Faza Sna/\"\n",
    "files = [f for f in os.listdir(folder) if f.endswith(\".csv\")]\n",
    "\n",
    "all_subjects = []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(os.path.join(folder, file))\n",
    "    df = df[df[\"Sleep_Stage\"] != \"P\"].copy()\n",
    "\n",
    "    signal = df[\"F4-M1\"].values\n",
    "    labels = df[\"Sleep_Stage\"].values\n",
    "    fs = 100\n",
    "    samples_per_epoch = fs * 30\n",
    "    num_epochs = len(signal) // samples_per_epoch\n",
    "\n",
    "    signal_epochs = np.array_split(signal[:num_epochs * samples_per_epoch], num_epochs)\n",
    "    label_epochs = np.array_split(labels[:num_epochs * samples_per_epoch], num_epochs)\n",
    "\n",
    "    normalized_epochs = []\n",
    "\n",
    "    for epoch in signal_epochs:\n",
    "        mean = np.mean(epoch)\n",
    "        std = np.std(epoch)\n",
    "        if std != 0:\n",
    "            norm_epoch = (epoch - mean) / std\n",
    "        else:\n",
    "            norm_epoch = epoch - mean\n",
    "        normalized_epochs.append(norm_epoch)\n",
    "\n",
    "    epoch_labels = [pd.Series(epoch).mode()[0] for epoch in label_epochs]\n",
    "    features = [compute_features(epoch) for epoch in normalized_epochs]\n",
    "    all_subjects.append((np.array(features), np.array(epoch_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd0bc621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(all_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "03ff0e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subject 1 - S002_PSG_df_updated.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.00      0.00      0.00        64\n",
      "          N2       0.41      0.63      0.50       334\n",
      "          N3       0.00      0.00      0.00         0\n",
      "           R       0.00      0.00      0.00        80\n",
      "           W       0.68      0.28      0.39       264\n",
      "\n",
      "    accuracy                           0.38       742\n",
      "   macro avg       0.22      0.18      0.18       742\n",
      "weighted avg       0.43      0.38      0.36       742\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subject 2 - S003_PSG_df_updated.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.00      0.00      0.00        32\n",
      "          N2       0.62      0.54      0.57       428\n",
      "          N3       1.00      0.07      0.14       136\n",
      "           R       0.52      0.13      0.20       119\n",
      "           W       0.24      0.86      0.38       113\n",
      "\n",
      "    accuracy                           0.42       828\n",
      "   macro avg       0.48      0.32      0.26       828\n",
      "weighted avg       0.59      0.42      0.40       828\n",
      "\n",
      "\n",
      "Subject 3 - S004_PSG_df_updated.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       1.00      0.01      0.02       163\n",
      "          N2       0.64      0.84      0.72       423\n",
      "          N3       0.00      0.00      0.00         1\n",
      "           R       0.00      0.00      0.00         0\n",
      "           W       0.53      0.26      0.35       248\n",
      "\n",
      "    accuracy                           0.51       835\n",
      "   macro avg       0.43      0.22      0.22       835\n",
      "weighted avg       0.68      0.51      0.47       835\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subject 4 - S005_PSG_df_updated.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.18      0.08      0.11        39\n",
      "          N2       0.71      0.81      0.76       479\n",
      "          N3       0.02      0.40      0.04         5\n",
      "           R       0.52      0.12      0.20       116\n",
      "           W       0.75      0.42      0.54        93\n",
      "\n",
      "    accuracy                           0.61       732\n",
      "   macro avg       0.44      0.37      0.33       732\n",
      "weighted avg       0.65      0.61      0.60       732\n",
      "\n",
      "\n",
      "Subject 5 - S006_PSG_df_updated.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.35      0.15      0.21       122\n",
      "          N2       0.54      0.75      0.63       290\n",
      "          N3       0.70      0.18      0.29       178\n",
      "           R       0.00      0.00      0.00         0\n",
      "           W       0.61      0.38      0.47       252\n",
      "\n",
      "    accuracy                           0.43       842\n",
      "   macro avg       0.44      0.29      0.32       842\n",
      "weighted avg       0.56      0.43      0.45       842\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subject 6 - S007_PSG_df_updated.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.27      0.12      0.16        26\n",
      "          N2       0.77      0.94      0.84       299\n",
      "          N3       0.64      0.35      0.45        26\n",
      "           R       0.23      0.46      0.30        41\n",
      "           W       0.99      0.79      0.88       428\n",
      "\n",
      "    accuracy                           0.80       820\n",
      "   macro avg       0.58      0.53      0.53       820\n",
      "weighted avg       0.84      0.80      0.80       820\n",
      "\n",
      "\n",
      "Subject 7 - S008_PSG_df_updated.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.40      0.38      0.39        42\n",
      "          N2       0.78      0.92      0.84       421\n",
      "          N3       0.78      0.20      0.32        89\n",
      "           R       0.83      0.60      0.69       137\n",
      "           W       0.57      0.88      0.69        58\n",
      "\n",
      "    accuracy                           0.74       747\n",
      "   macro avg       0.67      0.60      0.59       747\n",
      "weighted avg       0.75      0.74      0.72       747\n",
      "\n",
      "\n",
      "Subject 8 - S009_PSG_df_updated.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.11      0.01      0.03        67\n",
      "          N2       0.81      0.89      0.85       409\n",
      "          N3       0.00      0.00      0.00         3\n",
      "           R       0.89      0.64      0.75        76\n",
      "           W       0.91      0.93      0.92       251\n",
      "\n",
      "    accuracy                           0.80       806\n",
      "   macro avg       0.54      0.50      0.51       806\n",
      "weighted avg       0.79      0.80      0.79       806\n",
      "\n",
      "\n",
      "Subject 9 - S010_PSG_df_updated.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.09      0.01      0.01       124\n",
      "          N2       0.93      0.66      0.77       458\n",
      "           R       0.17      0.51      0.25        85\n",
      "           W       0.56      0.82      0.66       156\n",
      "\n",
      "    accuracy                           0.58       823\n",
      "   macro avg       0.44      0.50      0.43       823\n",
      "weighted avg       0.65      0.58      0.58       823\n",
      "\n",
      "\n",
      "Subject 10 - S011_PSG_df_updated.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.05      0.03      0.04        30\n",
      "          N2       0.62      0.98      0.76       423\n",
      "          N3       0.96      0.19      0.31       140\n",
      "           R       0.76      0.17      0.27       175\n",
      "           W       0.45      0.60      0.51        45\n",
      "\n",
      "    accuracy                           0.61       813\n",
      "   macro avg       0.57      0.39      0.38       813\n",
      "weighted avg       0.68      0.61      0.54       813\n",
      "\n",
      "\n",
      "Subject 11 - S012_PSG_df_updated.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.37      0.14      0.20       123\n",
      "          N2       0.86      0.73      0.79       435\n",
      "          N3       0.00      0.00      0.00         0\n",
      "           R       0.52      0.63      0.57       124\n",
      "           W       0.58      0.90      0.71       172\n",
      "\n",
      "    accuracy                           0.67       854\n",
      "   macro avg       0.47      0.48      0.45       854\n",
      "weighted avg       0.68      0.67      0.66       854\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subject 12 - S013_PSG_df_updated.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.15      0.11      0.12        19\n",
      "          N2       0.77      0.98      0.86       495\n",
      "          N3       0.17      0.01      0.02        82\n",
      "           R       0.94      0.64      0.76       152\n",
      "           W       0.68      0.68      0.68        37\n",
      "\n",
      "    accuracy                           0.78       785\n",
      "   macro avg       0.54      0.48      0.49       785\n",
      "weighted avg       0.72      0.78      0.73       785\n",
      "\n",
      "\n",
      "Subject 13 - S014_PSG_df_updated.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.15      0.16      0.15        31\n",
      "          N2       0.66      0.95      0.78       431\n",
      "          N3       1.00      0.02      0.04       106\n",
      "           R       0.21      0.36      0.27        33\n",
      "           W       0.88      0.36      0.51       194\n",
      "\n",
      "    accuracy                           0.63       795\n",
      "   macro avg       0.58      0.37      0.35       795\n",
      "weighted avg       0.72      0.63      0.57       795\n",
      "\n",
      "\n",
      "Subject 14 - S015_PSG_df_updated.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          N1       0.15      0.06      0.08        72\n",
      "          N2       0.84      0.56      0.67       546\n",
      "          N3       0.90      0.35      0.50        75\n",
      "           R       0.52      0.12      0.20       190\n",
      "           W       0.14      1.00      0.25        71\n",
      "\n",
      "    accuracy                           0.45       954\n",
      "   macro avg       0.51      0.42      0.34       954\n",
      "weighted avg       0.68      0.45      0.49       954\n",
      "\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "reports = []\n",
    "\n",
    "for i in range(len(all_subjects)):\n",
    "    X_test, y_test = all_subjects[i]\n",
    "    X_train = np.vstack([all_subjects[j][0] for j in range(len(all_subjects)) if j != i])\n",
    "    y_train = np.concatenate([all_subjects[j][1] for j in range(len(all_subjects)) if j != i])\n",
    "\n",
    "    y_train_enc = le.fit_transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train_enc)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(f\"\\nSubject {i + 1} - {files[i]}\")\n",
    "    unique_labels = np.unique(np.concatenate([y_test_enc, y_pred]))\n",
    "    print(classification_report(\n",
    "        y_test_enc,\n",
    "        y_pred,\n",
    "        labels=unique_labels,\n",
    "        target_names=le.inverse_transform(unique_labels)\n",
    "    ))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
